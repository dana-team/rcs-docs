# Autoscale Defaults

The following values are used for all `KSVC` CRs, which are created by `Capp` CRs. The values are also specified in the `config-autoscaler` ConfigMap in the `knative-serving` namespace:

| Parameter                 | Value           | Explanation                                                                                                                                                                                      |
| ----------------------------------- | --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `container-concurrency-target-percentage` | "70"          | Specifies the target percentage of maximum concurrent requests the Container can handle. This value is used to determine how much of the maximum concurrency to use in a stable state. It affects the average number of requests that the revision pods will receive. Fractional values (e.g., 0.7) are also accepted. It's important to note that this value affects the average number of requests per revision pod, not the actual number of concurrent requests the user container may receive. |
| `container-concurrency-target-default` | "100"           | Specifies the default target concurrency when the Revision specifies unlimited concurrency. In other words, when the revision does not explicitly set a container concurrency value, the Autoscaler will target this value for concurrency. This acts as a "soft limit" for scaling the application based on concurrency. It influences the number of pods created but doesn't impact the number of individual requests each pod can handle. |
| `requests-per-second-target-default` | "200"           | This configuration defines the default target number of requests per second (RPS) when the Revision specifies unlimited RPS. When scaling is based on RPS, this value is the default target that the Autoscaler will try to maintain for each revision. |
| `target-burst-capacity`             | "211"           | The target burst capacity specifies the expected size of bursts in concurrent requests that the system operator anticipates the system will receive. The Autoscaler uses this value to determine when to introduce an Activator into the request path to prevent queuing. If this value is set to 0, the Activator will only be introduced when the revision is scaled down to 0. If it's greater than 0 and `container-concurrency-target-percentage` is 100% or 1.0, the Activator will always be in the request path. |
| `stable-window`                     | "60s"           | The stable window defines the duration in seconds during which the Autoscaler calculates the average concurrency for making scaling decisions. It's essential that this value is in whole seconds. |
| `panic-window-percentage`           | "10.0"          | This configuration option specifies the percentage of the stable window that is used for calculating the panic mode window. When the observed average concurrency during the panic window reaches the `panic-threshold-percentage` of the target concurrency, the Autoscaler enters panic mode. The value is rounded to the closest whole second, with a minimum of 1 second. |
| `panic-threshold-percentage`        | "200.0"         | The percentage of the container concurrency target at which the Autoscaler enters panic mode when reached within the panic window. This means that if the observed average concurrency during the panic window exceeds this threshold, the Autoscaler will take action to address the increased load. |
| `max-scale-up-rate`                 | "1000.0"        | This configuration limits the rate at which the Autoscaler will increase the pod count. It is expressed as the maximum ratio of desired pods to observed pods. For example, with a value of "1000.0," the number of pods can increase at most from N to 2N over a single Autoscaler period (2 seconds). |
| `max-scale-down-rate`               | "2.0"           | Similar to `max-scale-up-rate`, this configuration limits the rate at which the Autoscaler will decrease the pod count. It is expressed as the maximum ratio of observed pods to desired pods. For instance, with a value of "2.0," the number of pods can decrease at most from N to N/2 over a single Autoscaler evaluation period (2 seconds). |
| `enable-scale-to-zero`              | "true"          | When set to "true," this configuration enables the scale-to-zero feature, allowing the Autoscaler to scale down to zero pods when there's no traffic. This feature helps save resources during idle periods. |
| `scale-to-zero-grace-period`        | "30s"           | The scale-to-zero grace period specifies the time that an inactive revision is left running before it is scaled down to zero. It's important to set a positive value, and a few seconds are recommended if you're using mesh networking. This period ensures network reprogramming completes and the activator is in the request path before scaling to zero. |
| `scale-to-zero-pod-retention-period` | "0s"           | This configuration defines the minimum amount of time the last pod will remain active after the Autoscaler decides to scale to zero. It is particularly useful in scenarios where pod startup is expensive and traffic is bursty. The larger of this value and `scale-to-zero-grace-period` determines how long the last pod remains active. |
| `pod-autoscaler-class`              | "kpa.autoscaling.knative.dev" | This setting specifies the default pod autoscaler class that should be used if none is explicitly specified. In this case, it defaults to the Knative Pod Autoscaler (KPA). |
| `activator-capacity`                | "100.0"         | The activator capacity defines the capacity of a single activator task. It is expressed as one concurrent request proxied by the activator and must be at least 1. This value is used in the computation of the Activator subset size. |
| `initial-scale`                     | "1"             | Initial scale is the cluster-wide default value for the initial target scale of a revision after creation, unless overridden by annotations. It must be greater than 0 unless `allow-zero-initial-scale` is set to true. |
| `allow-zero-initial-scale`          | "false"         | This configuration controls whether either the cluster-wide `initial-scale` flag or the "autoscaling.knative.dev/initialScale" annotation can be set to 0. If set to "true," it allows scaling to zero. |
| `min-scale`                         | "0"             | Min scale is the cluster-wide default value for the minimum scale of a revision, unless overridden by annotations. |
| `max-scale`                         | "0"             | Max scale is the cluster-wide default value for the maximum scale of a revision, unless overridden by the "autoscaling.knative.dev/maxScale" annotation. If set to "0," the revision has no maximum scale. |
| `scale-down-delay`                  | "0s"            | Scale down delay is the amount of time that must pass at reduced concurrency before a scale-down decision is applied. This can be useful to maintain a replica count and avoid a cold start penalty if more requests come in within the scale-down delay period. |
| `max-scale-limit`                   | "0"             | Max scale limit sets the maximum permitted value for the max scale of a revision. When set to a positive value, a revision with a maxScale above that value (including a maxScale of "0" for unlimited scaling) is disallowed. A value of "0" allows any limit, including unlimited scaling. |

In addition, every `Capp` is created with the following value, which cannot be set globally in the cluster and has to be specified per Knative Revision:

| Parameter               | Value | Explanation                                                                                                                          |
| ----------------------- | ----- | ------------------------------------------------------------------------------------------------------------------------------------ |
| `activation-scale` | 3 |  Controls the minimum number of replicas that will be created when the Revision scales up from zero. After the Revision has reached this scale one time, this value is ignored. This means that the Revision will scale down after the activation scale is reached if the actual traffic received needs a smaller scale.  When the Revision is created, the larger of activation scale and lower bound is automatically chosen as the initial target scale.                   |
